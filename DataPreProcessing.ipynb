{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6b9fb50-0b80-4835-8cea-3113ad383c8c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d8f2f7-515f-486d-900e-f12db7759461",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d69b835-692f-4a2d-afcc-46a611710f13",
   "metadata": {},
   "source": [
    "### Compute aggregate results over raw completions for random flip generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c1d882-bcd2-4274-b51e-0d5013725c4e",
   "metadata": {},
   "source": [
    "#### Process flip data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4bb5db91-8689-4da1-935f-a0aa8d21b8a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "llm_names = ['gpt-4-0613', \n",
    "             'gpt-4-0314', \n",
    "             'gpt-3.5-turbo-0613', \n",
    "             'gpt-3.5-turbo-0301',\n",
    "             'gpt-3.5-turbo-instruct',\n",
    "             'text-davinci-003', \n",
    "             'text-davinci-002', \n",
    "             'text-davinci-001', \n",
    "             'text-curie-001', \n",
    "             'text-babbage-001', \n",
    "             'text-ada-001']\n",
    "\n",
    "llm_raw = {llm: pickle.load(open(f'out/gen_flips1/gen_flips_{llm}.pk', 'rb')) + \\       # dir formerly: 9-2\n",
    "                (pickle.load(open(f'out/gen_flips2/gen_flips_{llm}.pk', 'rb')) if llm != 'gpt-3.5-turbo-instruct' else [])    # dir formerly: 09-21-2023_18-15-13\n",
    "           for llm in llm_names}\n",
    "\n",
    "llm_data = defaultdict(lambda: defaultdict(list))\n",
    "for llm, res in llm_raw.items():\n",
    "    for r in res:\n",
    "        flips = res_to_flips(r, print_misses=False)['flips']\n",
    "        llm_data[llm][r['p_tails']].append(flips)\n",
    "\n",
    "llm_data = {k: dict(v) for k, v in llm_data.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44a11c91-c32f-442b-a059-8d3c2e337199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from multiprocessing import Pool\n",
    "\n",
    "# all_args = [(llm, p_tails, llm_flips, fit_models, 50) for llm, flips_by_ptails in llm_data.items()\n",
    "#                                       for p_tails, llm_flips in flips_by_ptails.items()]\n",
    "# with Pool(15) as pool:\n",
    "#     llm_fit_res = list(tqdm(\n",
    "#         pool.imap(get_results, all_args), total=len(all_args)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17fff8eb-6ea9-42f0-9528-0350ebaeefd7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                              | 0/9 [00:00<?, ?it/s]\n",
      "  0%|                                                                                                                                             | 0/13 [00:00<?, ?it/s]\u001b[A\n",
      "  8%|██████████▏                                                                                                                          | 1/13 [00:12<02:27, 12.29s/it]\u001b[A\n",
      " 15%|████████████████████▍                                                                                                                | 2/13 [00:25<02:23, 13.09s/it]\u001b[A\n",
      " 23%|██████████████████████████████▋                                                                                                      | 3/13 [00:38<02:09, 12.97s/it]\u001b[A\n",
      " 31%|████████████████████████████████████████▉                                                                                            | 4/13 [00:50<01:53, 12.64s/it]\u001b[A\n",
      " 38%|███████████████████████████████████████████████████▏                                                                                 | 5/13 [01:02<01:39, 12.43s/it]\u001b[A\n",
      " 46%|█████████████████████████████████████████████████████████████▍                                                                       | 6/13 [01:15<01:26, 12.34s/it]\u001b[A\n",
      " 54%|███████████████████████████████████████████████████████████████████████▌                                                             | 7/13 [01:27<01:13, 12.32s/it]\u001b[A\n",
      " 62%|█████████████████████████████████████████████████████████████████████████████████▊                                                   | 8/13 [01:39<01:01, 12.39s/it]\u001b[A\n",
      " 69%|████████████████████████████████████████████████████████████████████████████████████████████                                         | 9/13 [01:52<00:50, 12.54s/it]\u001b[A\n",
      " 77%|█████████████████████████████████████████████████████████████████████████████████████████████████████▌                              | 10/13 [02:06<00:38, 12.79s/it]\u001b[A\n",
      " 85%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                    | 11/13 [02:18<00:25, 12.75s/it]\u001b[A\n",
      " 92%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊          | 12/13 [02:30<00:12, 12.45s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [02:42<00:00, 12.48s/it]\u001b[A\n",
      " 11%|██████████████▊                                                                                                                      | 1/9 [02:42<21:37, 162.19s/it]\n",
      "  0%|                                                                                                                                             | 0/13 [00:00<?, ?it/s]\u001b[A\n",
      "  8%|██████████▏                                                                                                                          | 1/13 [00:12<02:34, 12.91s/it]\u001b[A\n",
      " 15%|████████████████████▍                                                                                                                | 2/13 [00:25<02:21, 12.87s/it]\u001b[A\n",
      " 23%|██████████████████████████████▋                                                                                                      | 3/13 [00:38<02:06, 12.60s/it]\u001b[A\n",
      " 31%|████████████████████████████████████████▉                                                                                            | 4/13 [00:55<02:05, 13.90s/it]\u001b[A\n",
      " 11%|██████████████▊                                                                                                                      | 1/9 [03:37<29:02, 217.77s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m llm, flips_by_ptails \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mlist\u001b[39m(llm_data\u001b[38;5;241m.\u001b[39mitems())[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m p_tails, llm_flips \u001b[38;5;129;01min\u001b[39;00m tqdm(flips_by_ptails\u001b[38;5;241m.\u001b[39mitems()):\n\u001b[0;32m----> 5\u001b[0m         r \u001b[38;5;241m=\u001b[39m \u001b[43mget_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp_tails\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mllm_flips\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfit_models\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m         llm_fit_res\u001b[38;5;241m.\u001b[39mappend(r)\n\u001b[1;32m      8\u001b[0m llm_fit_res \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(llm_fit_res)\n",
      "File \u001b[0;32m~/research/coins/utils.py:419\u001b[0m, in \u001b[0;36mget_results\u001b[0;34m(llm_name, p_tails, llm_flips, fit_models, seq_len, n_samples)\u001b[0m\n\u001b[1;32m    415\u001b[0m     sim_flips \u001b[38;5;241m=\u001b[39m [model\u001b[38;5;241m.\u001b[39msample(seq_len) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_samples)]\n\u001b[1;32m    417\u001b[0m     gzip_agg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(gzip_compress([f \u001b[38;5;28;01mfor\u001b[39;00m flips \u001b[38;5;129;01min\u001b[39;00m sim_flips \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(flips)]))\n\u001b[0;32m--> 419\u001b[0m     rows \u001b[38;5;241m=\u001b[39m [make_flips_row(flips, llm_name, model_name, goal_p, gzip_agg\u001b[38;5;241m=\u001b[39mgzip_agg) \u001b[38;5;28;01mfor\u001b[39;00m flips \u001b[38;5;129;01min\u001b[39;00m sim_flips]\n\u001b[1;32m    420\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df, pd\u001b[38;5;241m.\u001b[39mDataFrame(rows)])\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[0;32m~/research/coins/utils.py:419\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    415\u001b[0m     sim_flips \u001b[38;5;241m=\u001b[39m [model\u001b[38;5;241m.\u001b[39msample(seq_len) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_samples)]\n\u001b[1;32m    417\u001b[0m     gzip_agg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(gzip_compress([f \u001b[38;5;28;01mfor\u001b[39;00m flips \u001b[38;5;129;01min\u001b[39;00m sim_flips \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(flips)]))\n\u001b[0;32m--> 419\u001b[0m     rows \u001b[38;5;241m=\u001b[39m [\u001b[43mmake_flips_row\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflips\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mllm_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgoal_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgzip_agg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgzip_agg\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m flips \u001b[38;5;129;01min\u001b[39;00m sim_flips]\n\u001b[1;32m    420\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df, pd\u001b[38;5;241m.\u001b[39mDataFrame(rows)])\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[0;32m~/research/coins/utils.py:388\u001b[0m, in \u001b[0;36mmake_flips_row\u001b[0;34m(flips, llm_name, model_name, goal_p, include_flips, **kwargs)\u001b[0m\n\u001b[1;32m    375\u001b[0m flips_ls \u001b[38;5;241m=\u001b[39m flips_arr\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m    377\u001b[0m run_avg \u001b[38;5;241m=\u001b[39m compute_running_prob(flips_ls, init_val\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mmean(flips_ls))\n\u001b[1;32m    378\u001b[0m row \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mllm\u001b[39m\u001b[38;5;124m'\u001b[39m: llm_name,\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m: model_name,\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgoal_p\u001b[39m\u001b[38;5;124m'\u001b[39m: goal_p,\n\u001b[1;32m    382\u001b[0m     \n\u001b[1;32m    383\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgzip\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mlen\u001b[39m(gzip_compress(flips_ls)),\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m: flips_arr\u001b[38;5;241m.\u001b[39mmean(),\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mp_A\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;28mabs\u001b[39m(flips_arr[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m flips_arr[\u001b[38;5;241m1\u001b[39m:])),\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlong_run\u001b[39m\u001b[38;5;124m'\u001b[39m: island_cumsum(flips_ls),\n\u001b[1;32m    387\u001b[0m \n\u001b[0;32m--> 388\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrun_avg_std\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_avg\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrun_avg_max\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mmax(run_avg),\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrun_avg_min\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mmin(run_avg),\n\u001b[1;32m    391\u001b[0m }\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_flips:\n\u001b[1;32m    393\u001b[0m     row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mflips\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m flips_to_str(flips_ls)\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mstd\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/code/python/envs/scienv/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3615\u001b[0m, in \u001b[0;36mstd\u001b[0;34m(a, axis, dtype, out, ddof, keepdims, where)\u001b[0m\n\u001b[1;32m   3612\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3613\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m std(axis\u001b[38;5;241m=\u001b[39maxis, dtype\u001b[38;5;241m=\u001b[39mdtype, out\u001b[38;5;241m=\u001b[39mout, ddof\u001b[38;5;241m=\u001b[39mddof, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 3615\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _methods\u001b[38;5;241m.\u001b[39m_std(a, axis\u001b[38;5;241m=\u001b[39maxis, dtype\u001b[38;5;241m=\u001b[39mdtype, out\u001b[38;5;241m=\u001b[39mout, ddof\u001b[38;5;241m=\u001b[39mddof,\n\u001b[1;32m   3616\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "llm_fit_res = []\n",
    "\n",
    "for llm, flips_by_ptails in tqdm(list(llm_data.items())[:-2]):\n",
    "    for p_tails, llm_flips in tqdm(flips_by_ptails.items()):\n",
    "        r = get_results(llm, p_tails, llm_flips, fit_models, seq_len=50)\n",
    "        llm_fit_res.append(r)\n",
    "\n",
    "llm_fit_res = pd.concat(llm_fit_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eef2eaa-ffdf-4409-9be0-ae1e7980ba99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "llm_sub_res = []\n",
    "seq_len = 50\n",
    "\n",
    "for llm, flips_by_ptails in tqdm(list(llm_data.items())[:-2]):\n",
    "    for p_tails, llm_flips in tqdm(flips_by_ptails.items(), leave=False):\n",
    "        # r = get_results(llm, p_tails, llm_flips, fit_models, seq_len=50)\n",
    "        r = get_sub_results(llm, p_tails, llm_flips, {mn: m for mn, m in fit_models.items()})  #  if mn in ['llm', 'Bernoulli', 'MC-a', 'MC-2', 'MC-10', 'Ground Truth', 'window-10']})  #, 'HMM-5', 'HMM-20']})\n",
    "        llm_sub_res += r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab3fd87-37a4-4b16-84b3-ace864ad8a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_fit_res.to_csv('out/gen_fit_res.csv')\n",
    "pickle.dump(llm_sub_res, open('out/gen_sub_res.pk', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf41c814-9033-4958-bca3-402fc76643ca",
   "metadata": {},
   "source": [
    "### load tree results for formal language generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "2fcf8963-50e2-42ad-8b86-f820c1f69338",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_names = [\n",
    "    #'gpt-4-0613', \n",
    "    #'gpt-4-0314', \n",
    "    #'gpt-3.5-turbo-0613', \n",
    "    #'gpt-3.5-turbo-0301',\n",
    "    'gpt-3.5-turbo-instruct-0914', \n",
    "    'text-davinci-003', \n",
    "    'text-davinci-002', \n",
    "    'text-davinci-001', \n",
    "    'text-curie-001', \n",
    "    'text-babbage-001', \n",
    "    'text-ada-001'\n",
    "]\n",
    "out_dir = 'out/gen_formal-lang'     # formerly: 11-17-2023_09-47-41\n",
    "\n",
    "llm_tree_raw = {llm: pickle.load(open(f'{out_dir}/tree_formal_{llm}.pk', 'rb')) for llm in llm_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "e8d5580c-1521-4d5d-9450-50feddbbf822",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_trees = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: defaultdict(list))))\n",
    "for llm, res in llm_tree_raw.items():\n",
    "    for r in res:\n",
    "        # del r['completion']\n",
    "        concept = tuple(r['concept'])\n",
    "        for x_len in r['x_len']:\n",
    "            for depth in r['depth']:\n",
    "                depth = depth[:-1] if depth else depth\n",
    "                depth = len(depth.split(','))\n",
    "                llm_trees[llm][concept][x_len][depth] += r  if type(r) in (list, tuple)  else [r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f167db6b-b584-404c-b5d3-8d828873157c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 0, 1),\n",
       " (30,),\n",
       " ('Tails, Tails, Tails, Tails, Tails,',),\n",
       " 'Tails, Heads, Tails, Tails, Heads, Tails, Tails, Heads, Tails, Tails, Heads, Tails, Tails, Heads, Tails, Tails, Heads, Tails, Tails, Heads, Tails, Tails, Heads, Tails, Tails, Heads, Tails, Tails, Heads, Tails, Tails, Tails, Tails, Tails, Tails,')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r['concept'], r['x_len'], r['depth'], r['prompt_args']['flips']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "dcf6527b-320b-4e28-a539-53d7f2bb2bbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('text-ada-001', (1, 0, 1), 30, 5)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(llm, concept, x_len, depth, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "868a8e37-50fc-4969-85ba-af1d67aa360d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert chat results to probabilities, since openai chat results didn't have logprobs available at the time (they do now! for now at least)\n",
    "#   I think there's a bug in my code, and I didn't end up getting this together to have formal language generation with chat models in the paper  🤷‍♂️\n",
    "\n",
    "llm_probs = defaultdict(lambda: defaultdict(dict))\n",
    "for llm, d1 in llm_trees.items():\n",
    "    for concept, d2 in d1.items():\n",
    "        for x_len, res in d2.items():\n",
    "            if llm.startswith('gpt'):\n",
    "                llm_probs[llm][concept][x_len] = chat_res_to_probs(res)\n",
    "            else:\n",
    "                llm_probs[llm][concept][x_len] = comp_res_to_probs(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8a5a84-ac48-4766-b1c1-010f0d65891a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
